{
  "hash": "a4073df8602030e18644cb0ba7f2ac8e",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: Project 2\nsubtitle: Artificial Neural Networks and Deep Learning\nengine: julia\n---\n\nImages of galaxies obtained by the Sloan Digital Sky Survey (SDSS) have been classified by different  people through a participatory science process (see this article: https://arxiv.org/abs/1308.3496). There  are tens of thousands of classified examples. However, there are even more images, and classifying them  all by humans would take an enormous amount of time.\n\nOur goal is therefore to develop a method to classify these images efficiently. We will use a convolutional neural network.  \n\nThere are 37 non-exclusive categories (a galaxy can belong to more than one group). Since classification is sometimes ambiguous, participants did not always get the same answers. For each galaxy, the  classification result is therefore a probability of belonging to one of the categories. To train the network,  we will therefore use the mean squared error (MSE) to compare the probabilities given by the network.  \n\n$$\nMSE = \\frac{1}{N} \\sum_{n} (x_n - y_n)^2  \n$$\n\nFor our final criterion (i.e., the one we will give as the answer at the very end), we will use the root of  the MSE (RMSE): $RMSE = \\sqrt{MSE}$. This is therefore a regression problem (37 output values y that  we are trying to predict with the model), although the ultimate goal is to classify galaxies.\n\n\n## Step 1: Data exploration\n\nThe images are in a folder called images_training_rev1. The probabilities for each class are in the file `training_solutions_rev1.csv`. GalaxyID gives the identifier and each file in the folder corresponds  to a GalaxyID (with a .jpg extension). To familiarize yourself with the data:  \n\n1. (Optional, not to be displayed in the submission) Import the CSV file and display the first few rows\n\n2. Display the galaxy with the highest probability for each class (a .jpg or .png image). The format is: (dim1, dim2, C) where C=3 in our case. (Please include these images in a single figure, displaying the category name above each image).\n\nDisplay the resulting figure with a brief explanation. Submit the code used to import the CSV and generate the figure.\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\ndir = \"docs/courses/epss298_DataAnalysis/projects/proj2\"\nif isdir(dir)\n    cd(dir)\n    Pkg.activate(\".\")\n    Pkg.resolve()\n    Pkg.instantiate()\nend\n```\n:::\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing CSV\nusing DataFrames\n\ngalaxy_data = CSV.read(\"data/training_solutions_rev1.csv\", DataFrame)\ntransform!(galaxy_data, names(galaxy_data, Float64) .=> x -> Float32.(x); renamecols=false)\n\nclass_columns = names(galaxy_data)[2:end]\n\nDESCRIPTIONS = [\n    \"Smooth\", \"Featured or disc\", \"Star or artifact\",\n    \"Edge on\", \"Not edge on\",\n    \"Bar through center\", \"No bar\",\n    \"Spiral\", \"No Spiral\",\n    \"No bulge\", \"Just noticeable bulge\", \"Obvious bulge\", \"Dominant bulge\",\n    \"Odd Feature\", \"No Odd Feature\",\n    \"Completely round\", \"In between\", \"Cigar shaped\",\n    \"Ring\", \"Lens or arc\", \"Disturbed\", \"Irregular\", \"Other\", \"Merger\", \"Dust lane\",\n    \"Rounded bulge\", \"Boxy bulge\", \"No bulge\",\n    \"Tightly wound arms\", \"Medium wound arms\", \"Loose wound arms\",\n    \"1 Spiral Arm\", \"2 Spiral Arms\", \"3 Spiral Arms\", \"4 Spiral Arms\",\n    \"More than four Spiral Arms\", \"Can't tell how many spiral arms\",\n]\n\nconst CDICT = Dict(class_columns .=> DESCRIPTIONS)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nDict{String, String} with 37 entries:\n  \"Class5.1\"  => \"No bulge\"\n  \"Class8.5\"  => \"Other\"\n  \"Class7.2\"  => \"In between\"\n  \"Class11.2\" => \"2 Spiral Arms\"\n  \"Class11.3\" => \"3 Spiral Arms\"\n  \"Class3.1\"  => \"Bar through center\"\n  \"Class8.2\"  => \"Lens or arc\"\n  \"Class7.1\"  => \"Completely round\"\n  \"Class6.2\"  => \"No Odd Feature\"\n  \"Class6.1\"  => \"Odd Feature\"\n  \"Class2.1\"  => \"Edge on\"\n  \"Class1.2\"  => \"Featured or disc\"\n  \"Class1.1\"  => \"Smooth\"\n  \"Class1.3\"  => \"Star or artifact\"\n  \"Class2.2\"  => \"Not edge on\"\n  \"Class5.4\"  => \"Dominant bulge\"\n  \"Class10.1\" => \"Tightly wound arms\"\n  \"Class4.1\"  => \"Spiral\"\n  \"Class8.1\"  => \"Ring\"\n  ⋮           => ⋮\n```\n:::\n:::\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing FileIO\nusing Images\n\nload_img(id) = Images.load(File{format\"JPEG\"}(\"data/images_training_rev1/$(id).jpg\"))\nload_processed_img(id) = Images.load(File{format\"JPEG\"}(\"data/processed_images/$(id).jpg\"))\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nload_processed_img (generic function with 1 method)\n```\n:::\n:::\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\n# Find the galaxy with highest probability for each class\nhighest_prob_df = DataFrame(\n    map(class_columns) do Class\n        max_idx = argmax(galaxy_data[!, Class])\n        GalaxyID = galaxy_data[max_idx, :GalaxyID]\n        Probability = galaxy_data[max_idx, Class]\n        (; Class, GalaxyID, Probability)\n    end\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n37×3 DataFrame\n Row │ Class      GalaxyID  Probability \n     │ String     Int64     Float32     \n─────┼──────────────────────────────────\n   1 │ Class1.1     105447     1.0\n   2 │ Class1.2     100859     1.0\n   3 │ Class1.3     356310     0.935147\n   4 │ Class2.1     344604     1.0\n   5 │ Class2.2     105009     1.0\n   6 │ Class3.1     205541     1.0\n   7 │ Class3.2     185561     1.0\n   8 │ Class4.1     105009     1.0\n  ⋮  │     ⋮         ⋮           ⋮\n  31 │ Class10.3    416488     0.996952\n  32 │ Class11.1    848818     0.886363\n  33 │ Class11.2    105009     1.0\n  34 │ Class11.3    121006     0.975913\n  35 │ Class11.4    233081     0.957\n  36 │ Class11.5    495381     0.938881\n  37 │ Class11.6    598442     0.753082\n                         22 rows omitted\n```\n:::\n:::\n\n\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing CairoMakie\nusing CairoMakie: Axis\n\nnum_classes = nrow(highest_prob_df)\n\nfunction plot_images(df, load; width=150, height=150)\n    fig = Figure()\n    # Calculate grid dimensions - aim for roughly square layout\n    ncols = ceil(Int, sqrt(num_classes))\n    nrows = ceil(Int, num_classes / ncols)\n    # Load and display each image\n    for (i, row) in enumerate(eachrow(highest_prob_df))\n        row_idx = div(i - 1, ncols) + 1\n        col_idx = mod(i - 1, ncols) + 1\n        title = \"$(row.Class)\\n$(CDICT[row.Class])\\nProb: $(round(row.Probability, digits=2))\"\n        ax = Axis(fig[row_idx, col_idx]; width, height, title,)\n        hidedecorations!(ax)\n        image!(ax, load(row.GalaxyID))\n    end\n    resize_to_layout!(fig)\n    return fig\nend\n\nplot_images(highest_prob_df, load_img)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n![](index_files/figure-typst/cell-6-output-1.svg){}\n:::\n:::\n\n\n\n\n## Step 2: Prepare the images\n\n> The initial format of the images is not optimal. The format is large (424x424) and there is a lot of  empty space around the galaxies. Write a code that performs the following tasks:\n\n### Crop, resize, and save images\n\n> 1. Crop the image to reduce the size by half around the center (212x212)\n> 2. Reduce the resolution so that the image has 64 pixels on each side  \n> 3. Save all pre-processed images in a new folder\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing ProgressMeter\nusing DataAugmentation\n\n@views function preprocess_image(img; crop_size=212)\n    cropped_img = DataAugmentation.apply(\n        DataAugmentation.CenterCrop((crop_size, crop_size)),\n        DataAugmentation.Image(img)\n    ) |> DataAugmentation.itemdata\n    return imresize(cropped_img, (64, 64))\nend\n\nfunction process_and_save_images(galaxy_ids, path)\n    mkpath(path)\n    @showprogress \"Processing images...\" for id in galaxy_ids\n        img_path = joinpath(path, \"$(id).jpg\")\n        !isfile(img_path) && save(img_path, preprocess_image(load_img(id)))\n    end\nend\n\n# Process and save all images\nprocess_and_save_images(galaxy_data.GalaxyID, \"data/processed_images\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\rProcessing images...   2%|▌                              |  ETA: 0:00:06\rProcessing images... 100%|███████████████████████████████| Time: 0:00:01\n```\n:::\n:::\n\n\n\n\n### Data split, Dataset, and DataLoader\n\n4. Using the GalaxyID from the CSV, randomly split the data into two subsets: training and testing.  We want 20% of the images to be used exclusively for testing. \n5. Define a Dataset that can import the data and probabilities for each class (one for training, one for testing).\n6. From the two Datasets, create two Dataloaders that use subsets of 64 images.\n\nDisplay the same figure as in Step 1, but with the images modified, explaining how the modifications were made. Submit the code used to modify the images and generate the figure.\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing MLUtils\n\n@views function get_labels(source, ids)\n    idx = searchsortedfirst.(Ref(source.GalaxyID), ids)\n    return source[idx, 2:end]\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nget_labels (generic function with 1 method)\n```\n:::\n:::\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\n# 5. Define a Julia Dataset equivalent for training and testing\nstruct GalaxyDataset{I,L,F}\n    ids::I\n    labels::L\n    load::F\nend\n\ntransform_img(img) = permutedims(channelview(img), (2, 3, 1))\n\nfunction Base.getindex(dataset::GalaxyDataset, idx)\n    ids = dataset.ids[idx]\n    img_arrays = convert(Array{Float32,4}, stack(transform_img ∘ dataset.load, ids; dims=4))\n    labels = convert(Matrix{Float32}, stack(get_labels.(Ref(dataset.labels), ids); dims=2))\n    return img_arrays, labels\nend\n\nBase.length(dataset::GalaxyDataset) = length(dataset.ids)\n\ntrain_ids, test_ids = splitobs(galaxy_data.GalaxyID, at=0.8, shuffle=true)\n\n# Create training and testing datasets\ntrain_dataset = GalaxyDataset(\n    train_ids,\n    galaxy_data,\n    load_processed_img\n)\n\ntest_dataset = GalaxyDataset(\n    test_ids,\n    galaxy_data,\n    load_processed_img\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nGalaxyDataset{SubArray{Int64, 1, SentinelArrays.ChainedVector{Int64, Vector{Int64}}, Tuple{Vector{Int64}}, false}, DataFrame, typeof(load_processed_img)}([382929, 544106, 446979, 964338, 347181, 846886, 122933, 938653, 218078, 520163  …  505764, 994191, 508567, 224858, 680758, 295420, 571359, 482977, 214376, 898745], 61578×38 DataFrame\n   Row │ GalaxyID  Class1.1  Class1.2  Class1.3  Class2.1   Class2.2  Class3.1 ⋯\n       │ Int64     Float32   Float32   Float32   Float32    Float32   Float32  ⋯\n───────┼────────────────────────────────────────────────────────────────────────\n     1 │   100008  0.383147  0.616853  0.0       0.0        0.616853  0.038452 ⋯\n     2 │   100023  0.327001  0.663777  0.009222  0.0311783  0.632599  0.46737\n     3 │   100053  0.765717  0.177352  0.056931  0.0        0.177352  0.0\n     4 │   100078  0.693377  0.238564  0.068059  0.0        0.238564  0.109493\n     5 │   100090  0.933839  0.0       0.066161  0.0        0.0       0.0      ⋯\n     6 │   100122  0.738832  0.238159  0.023009  0.0        0.238159  0.0\n     7 │   100123  0.462492  0.456033  0.081475  0.0        0.456033  0.0\n     8 │   100128  0.687783  0.288344  0.023873  0.0        0.288344  0.069098\n   ⋮   │    ⋮         ⋮         ⋮         ⋮          ⋮         ⋮          ⋮    ⋱\n 61572 │   999900  0.460239  0.511396  0.028365  0.109439   0.401957  0.0      ⋯\n 61573 │   999936  0.545443  0.454557  0.0       0.0568196  0.397737  0.126909\n 61574 │   999948  0.510379  0.489621  0.0       0.0592069  0.430414  0.0\n 61575 │   999950  0.901216  0.098784  0.0       0.0        0.098784  0.0\n 61576 │   999958  0.202841  0.777376  0.019783  0.116962   0.660414  0.067245 ⋯\n 61577 │   999964  0.091     0.909     0.0       0.04545    0.86355   0.022452\n 61578 │   999967  0.767     0.14      0.093     0.0        0.14      0.0\n                                               32 columns and 61563 rows omitted, load_processed_img)\n```\n:::\n:::\n\n\n\n#### 6. Create DataLoaders with batch size\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\ntrain_loader = DataLoader(train_dataset, batchsize=32)\ntest_loader = DataLoader(test_dataset, batchsize=32)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n385-element DataLoader(::GalaxyDataset{SubArray{Int64, 1, SentinelArrays.ChainedVector{Int64, Vector{Int64}}, Tuple{Vector{Int64}}, false}, DataFrame, typeof(load_processed_img)}, batchsize=32)\n  with first element:\n  (64×64×3×32 Array{Float32, 4}, 37×32 Matrix{Float32},)\n```\n:::\n:::\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nplot_images(highest_prob_df, load_processed_img)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n![](index_files/figure-typst/cell-11-output-1.svg){}\n:::\n:::\n\n\n\n\n## Step 3: Defining a CNN\n\n> The data is now ready to be analyzed. Next, we need to define a CNN that will take the 64x64 images with 3 colors as input and give us a probability for the 37 classes as output. To start, define a CNN with the following elements (this is an adaptation of the CNN we used  with the FashionMNIST data):  \n\n1. Convolution layer with 6 output filters, a 5-pixel kernel, and a padding of 3.  \n2. Convolution layer with 16 output filters, a 5-pixel kernel, and a padding of 3.  \n3. Fully connected layer with 120 output neurons  \n4. Fully connected layer with 84 output neurons  \n5. Final layer with logits for the 37 classes.  \n6. We need to convert the 37 classes to probabilities. Which function seen in class allows us to convert logits to a value between 0 and 1? (Note: The probabilities are not mutually exclusive!)  \n\n> After each convolution layer, use batch normalization, ReLU activation, and pooling with a kernel size of 2. \n> Between the fully connected layers, use a ReLU activation function (except at the output of the final layer). Don’t forget to flatten the images between the last convolution layer and the first fully connected  layer.\n\nIn the report, explain the general structure and function of the different layers. Submit the  code that defines this CNN.\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nfunction get_output_width(width, kernel_size; stride=1, padding=0, dilation=1)\n    floor(Int,\n        (width + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1\n    )\nend\n\nusing Chain: @chain\n\n@chain 64 begin\n    get_output_width(5; padding=3)\n    get_output_width(2; stride=2)\n    get_output_width(5; padding=3)\n    get_output_width(2; stride=2)\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n17\n```\n:::\n:::\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing Random\nusing Lux\nusing Optimisers\nusing Zygote\n\nrng = Random.default_rng()\nRandom.seed!(rng, 42)\n\nfunction build_cnn_model(; num_classes=37, pad=3)\n    return Chain(\n        Chain(\n            Conv((5, 5), 3 => 6; pad),\n            BatchNorm(6, relu),\n            MaxPool((2, 2)),\n        ),\n        Chain(\n            Conv((5, 5), 6 => 16; pad),\n            BatchNorm(16, relu),\n            MaxPool((2, 2)),\n        ),\n        FlattenLayer(; N=3),\n        Chain(\n            Dense(4624 => 120, relu),\n            Dense(120 => 84, relu),\n            Dense(84 => num_classes, sigmoid);\n            name=\"Fully connected layer\"\n        )\n    )\nend\n\n# Initialize the model\nmodel = build_cnn_model()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nChain(\n    layer_1 = Chain(\n        layer_1 = Conv((5, 5), 3 => 6, pad=3),  # 456 parameters\n        layer_2 = BatchNorm(6, relu, affine=true, track_stats=true),  # 12 parameters, plus 13\n        layer_3 = MaxPool((2, 2)),\n    ),\n    layer_2 = Chain(\n        layer_1 = Conv((5, 5), 6 => 16, pad=3),  # 2_416 parameters\n        layer_2 = BatchNorm(16, relu, affine=true, track_stats=true),  # 32 parameters, plus 33\n        layer_3 = MaxPool((2, 2)),\n    ),\n    layer_3 = FlattenLayer{Static.StaticInt{3}}(static(3)),\n    layer_4 = Fully connected layer(\n        layer_1 = Dense(4624 => 120, relu),  # 555_000 parameters\n        layer_2 = Dense(120 => 84, relu),  # 10_164 parameters\n        layer_3 = Dense(84 => 37, σ),   # 3_145 parameters\n    ),\n)         # Total: 571_225 parameters,\n          #        plus 46 states.\n```\n:::\n:::\n\n\n\nCreate dummy input to test the model\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nps, st = Lux.setup(rng, model);\nx = rand(rng, Float32, 64, 64, 3, 2)  # (height, width, channels, batch_size)\nmodel(x, ps, Lux.testmode(st))\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n(Float32[0.5226176 0.5963492; 0.7555507 0.75195336; … ; 0.43180552 0.5062954; 0.64954376 0.6692772], (layer_1 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()), layer_3 = NamedTuple()), layer_2 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()), layer_3 = NamedTuple()), layer_3 = NamedTuple(), layer_4 = (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple())))\n```\n:::\n:::\n\n\n\n\n## Step 4: Training the network\n\n> Once the network is defined, it must be trained to recognize galaxies. Adapt the training and testing  loops we saw in class. Use the following hyperparameters, then train the model. \n\n1. MSE objective function\n2. Adam optimizer\n3. 6 epochs\n\n> Record the value of the objective function for each epoch, for the training and test data separately. Once  training is complete, display the evolution of the objective function for the training and test data.  \n\nIn the report, explain the training process and display the evolution of the objective function.  Submit the code used to train the network.\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing Printf\n\nfunction evaluate_model(model, ps, st, dataloader, lossfn)\n    total_loss = 0.0f0\n    total_batches = 0\n    st = Lux.testmode(st)\n    @showprogress \"Testing...\" for (x, y) in dataloader\n        # Forward pass\n        y_pred = first(model(x, ps, st))\n        # Compute loss\n        loss = lossfn(y_pred, y)\n        total_loss += loss\n        total_batches += 1\n    end\n    return total_loss / total_batches\nend\n\nfunction init_evaluate_model(model, ps, st, train_loader, test_loader, lossfn=MSELoss(); verbose=true)\n    train_loss = evaluate_model(model, ps, st, train_loader, lossfn)\n    test_loss = evaluate_model(model, ps, st, test_loader, lossfn)\n    if verbose\n        @printf \"Initial: Train Loss %4.5f, Test Loss %4.5f\\n\" train_loss test_loss\n    end\n    return train_loss, test_loss\nend\n\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\ninit_evaluate_model (generic function with 2 methods)\n```\n:::\n:::\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing JLD2\n\nfunction train_model!(model, ps, st, train_loader, test_loader; op=Adam(0.003f0), epochs=6)\n    train_state = Training.TrainState(model, ps, st, op)\n\n    ad = AutoZygote()\n    lossfn = MSELoss()\n\n    # Initialize arrays to store losses\n    train_losses = Float32[]\n    test_losses = Float32[]\n\n    for epoch in 1:epochs\n        # Training phase\n        total_loss = 0.0f0\n        total_batches = 0\n\n        @showprogress \"Training...\" for data in train_loader\n            _, loss, _, train_state = Training.single_train_step!(\n                ad, lossfn,\n                data, train_state\n            )\n            total_loss += loss\n            total_batches += 1\n        end\n        # Calculate average training loss for this epoch\n        train_loss = total_loss / total_batches\n        push!(train_losses, train_loss)\n\n        test_loss = evaluate_model(model, train_state.parameters, train_state.states, test_loader, lossfn)\n        push!(test_losses, test_loss)\n        @printf \"Epoch [%3d]: Train Loss %4.5f, Test Loss %4.5f\\n\" epoch train_loss test_loss\n    end\n\n    return train_state, train_losses, test_losses\nend\n\n# load file if it exists\nepochs = 6\nif isfile(\"trained_model.jld2\")\n    @load \"trained_model.jld2\" ps_trained st_trained train_losses test_losses\nelse\n    # Evaluate initial losses before training\n    initial_train_loss, initial_test_loss = init_evaluate_model(model, ps, st, train_loader, test_loader; verbose=true)\n\n    # Train the model and record both training and testing losses\n    train_state, train_losses, test_losses = train_model!(model, ps, st, train_loader, test_loader; epochs)\n\n    # Append training losses to the initial losses\n    prepend!(train_losses, initial_train_loss)\n    prepend!(test_losses, initial_test_loss)\n\n    ps_trained, st_trained = train_state.parameters, train_state.states\n    @save \"trained_model.jld2\" ps_trained st_trained train_losses test_losses\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n4-element Vector{Symbol}:\n :ps_trained\n :st_trained\n :train_losses\n :test_losses\n```\n:::\n:::\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\n# Visualize the evolution of the training and testing loss\nfig = Figure()\nax = Axis(fig[1, 1],\n    xlabel=\"Epoch\",\n    ylabel=\"Mean Squared Error\",\n    title=\"Training and Testing Loss Evolution\",\n)\nscatterlines!(0:epochs, train_losses, linewidth=3, color=:blue, label=\"Training Loss\")\nscatterlines!(0:epochs, test_losses, linewidth=3, color=:red, label=\"Testing Loss\")\naxislegend(ax, position=:rt)\n\nfig\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n![](index_files/figure-typst/cell-17-output-1.svg){}\n:::\n:::\n\n\n\n## Step 5: Model evaluation\n\n> With the trained model, what is the RMSE value for the test data? For reference, a simple solution  that uses the average color of the 100 central pixels (10x10) gives an RMSE of 0.16194. How does your neural network compare to this method?\n> The dataset we are studying was used in a Kaggle competition several years ago:  https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge. Several people have attempted to find a  solution that gives the smallest possible RMSE. The solutions are ranked in the Leaderboard tab. How does the solution obtained in Step 4 rank?\n> In the report, report the RMSE and discuss the comparison with a simplistic method (central pixels). Submit the code used to calculate the RMSE.\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\ncnn_rmse = sqrt(test_losses[end])\nsimple_rmse_ref = 0.16194\nimprovement = round(((simple_rmse_ref - cnn_rmse) / simple_rmse_ref * 100), digits=2)\n\n@info \"CNN RMSE on train data: \" sqrt(train_losses[end])\n@info \"CNN RMSE on test data: \" sqrt(test_losses[end])\n@info \"Improvement: $(improvement) %\"\n\nif cnn_rmse < simple_rmse_ref\n    println(\"\\nOur CNN model outperforms the simple central pixels method!\")\n    println(\"This demonstrates that the CNN can learn complex patterns across the entire image rather than just using the central region.\")\nelse\n    println(\"\\nOur CNN model doesn't outperform the simple method yet.\")\n    println(\"This could be due to several factors:\")\n    println(\"1. Limited training epochs\")\n    println(\"2. Model architecture might need optimization\")\n    println(\"3. Learning rate or other hyperparameters might need tuning\")\nend\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n┌ Info: CNN RMSE on train data: \n└   sqrt(train_losses[end]) = 0.108268715f0\n┌ Info: CNN RMSE on test data: \n└   sqrt(test_losses[end]) = 0.11684338f0\n[ Info: Improvement: 27.85 %\n\nOur CNN model outperforms the simple central pixels method!\nThis demonstrates that the CNN can learn complex patterns across the entire image rather than just using the central region.\n```\n:::\n:::\n\n\n\n\n## Step 6: Model modification\n\n> In class, we saw different ways to improve model performance (regularization, dropout, data augmentation, adding layers, changing the model configuration or training process). Modify the model and  evaluate the effect of the changes on training. You can also completely redefine the model, either using a known architecture (e.g., ResNet) or an original architecture. How does the performance compare to  that of Steps 3-4-5? Can you explain why the changes had this effect?\n\nGrading scale:\n\n1. Any simple modification to the model ensures at least 6/10\n2. Additional modifications are worth 1 point each, up to a total of 10/10\n3. Rewriting a completely different architecture with a similar or larger number of parameters and at  least two hidden layers automatically earns full points (10/10)\n4. Model performance does not earn any additional points. The goal is really to get you to explore  possible modifications!  In the report, indicate what modifications you made, the effect they had, and why they had that  effect. Also include a comparison of the RMSE with the previous steps. Submit the modified  code for this section.\n\n### Using ResNet for Galaxy Classification\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing Boltz, Metalhead, Lux\n\n# Function to create a modified ResNet for our galaxy classification task\nfunction build_resnet_model(; num_classes=37)\n    # Get the base ResNet-18 model\n    resnet = Vision.ResNet(18)\n\n    # Extract all layers except the final classification layer\n    base_layers = resnet.layer.layer_1\n\n    # Create a new final layer for our 37-class multi-label classification\n    final_layer = Chain(\n        AdaptiveMeanPool((1, 1)),\n        FlattenLayer(; N=3),\n        Dense(512 => num_classes, sigmoid)\n    )\n\n    # Combine the base layers with our new classification head\n    return Chain(base_layers, final_layer)\nend\n\n# Initialize the ResNet model\nresnet_model = build_resnet_model()\nresnet_ps, resnet_st = Lux.setup(rng, resnet_model)\n\n# Show model structure\nresnet_model\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nChain(\n    layer_1 = Chain(\n        layer_1 = Chain(\n            layer_1 = Conv((7, 7), 3 => 64, pad=3, stride=2, use_bias=false),  # 9_408 parameters\n            layer_2 = BatchNorm(64, relu, affine=true, track_stats=true),  # 128 parameters, plus 129\n            layer_3 = MaxPool((3, 3), pad=1, stride=2),\n        ),\n        layer_2 = Chain(\n            layer_1 = Parallel(\n                connection = addact(NNlib.relu, ...),\n                layer_1 = NoOpLayer(),\n                layer_2 = Chain(\n                    layer_1 = Conv((3, 3), 64 => 64, pad=1, use_bias=false),  # 36_864 parameters\n                    layer_2 = BatchNorm(64, affine=true, track_stats=true),  # 128 parameters, plus 129\n                    layer_3 = WrappedFunction(relu),\n                    layer_4 = Conv((3, 3), 64 => 64, pad=1, use_bias=false),  # 36_864 parameters\n                    layer_5 = BatchNorm(64, affine=true, track_stats=true),  # 128 parameters, plus 129\n                ),\n            ),\n            layer_2 = Parallel(\n                connection = addact(NNlib.relu, ...),\n                layer_1 = NoOpLayer(),\n                layer_2 = Chain(\n                    layer_1 = Conv((3, 3), 64 => 64, pad=1, use_bias=false),  # 36_864 parameters\n                    layer_2 = BatchNorm(64, affine=true, track_stats=true),  # 128 parameters, plus 129\n                    layer_3 = WrappedFunction(relu),\n                    layer_4 = Conv((3, 3), 64 => 64, pad=1, use_bias=false),  # 36_864 parameters\n                    layer_5 = BatchNorm(64, affine=true, track_stats=true),  # 128 parameters, plus 129\n                ),\n            ),\n        ),\n        layer_3 = Chain(\n            layer_1 = Parallel(\n                connection = addact(NNlib.relu, ...),\n                layer_1 = Chain(\n                    layer_1 = Conv((1, 1), 64 => 128, stride=2, use_bias=false),  # 8_192 parameters\n                    layer_2 = BatchNorm(128, affine=true, track_stats=true),  # 256 parameters, plus 257\n                ),\n                layer_2 = Chain(\n                    layer_1 = Conv((3, 3), 64 => 128, pad=1, stride=2, use_bias=false),  # 73_728 parameters\n                    layer_2 = BatchNorm(128, affine=true, track_stats=true),  # 256 parameters, plus 257\n                    layer_3 = WrappedFunction(relu),\n                    layer_4 = Conv((3, 3), 128 => 128, pad=1, use_bias=false),  # 147_456 parameters\n                    layer_5 = BatchNorm(128, affine=true, track_stats=true),  # 256 parameters, plus 257\n                ),\n            ),\n            layer_2 = Parallel(\n                connection = addact(NNlib.relu, ...),\n                layer_1 = NoOpLayer(),\n                layer_2 = Chain(\n                    layer_1 = Conv((3, 3), 128 => 128, pad=1, use_bias=false),  # 147_456 parameters\n                    layer_2 = BatchNorm(128, affine=true, track_stats=true),  # 256 parameters, plus 257\n                    layer_3 = WrappedFunction(relu),\n                    layer_4 = Conv((3, 3), 128 => 128, pad=1, use_bias=false),  # 147_456 parameters\n                    layer_5 = BatchNorm(128, affine=true, track_stats=true),  # 256 parameters, plus 257\n                ),\n            ),\n        ),\n        layer_4 = Chain(\n            layer_1 = Parallel(\n                connection = addact(NNlib.relu, ...),\n                layer_1 = Chain(\n                    layer_1 = Conv((1, 1), 128 => 256, stride=2, use_bias=false),  # 32_768 parameters\n                    layer_2 = BatchNorm(256, affine=true, track_stats=true),  # 512 parameters, plus 513\n                ),\n                layer_2 = Chain(\n                    layer_1 = Conv((3, 3), 128 => 256, pad=1, stride=2, use_bias=false),  # 294_912 parameters\n                    layer_2 = BatchNorm(256, affine=true, track_stats=true),  # 512 parameters, plus 513\n                    layer_3 = WrappedFunction(relu),\n                    layer_4 = Conv((3, 3), 256 => 256, pad=1, use_bias=false),  # 589_824 parameters\n                    layer_5 = BatchNorm(256, affine=true, track_stats=true),  # 512 parameters, plus 513\n                ),\n            ),\n            layer_2 = Parallel(\n                connection = addact(NNlib.relu, ...),\n                layer_1 = NoOpLayer(),\n                layer_2 = Chain(\n                    layer_1 = Conv((3, 3), 256 => 256, pad=1, use_bias=false),  # 589_824 parameters\n                    layer_2 = BatchNorm(256, affine=true, track_stats=true),  # 512 parameters, plus 513\n                    layer_3 = WrappedFunction(relu),\n                    layer_4 = Conv((3, 3), 256 => 256, pad=1, use_bias=false),  # 589_824 parameters\n                    layer_5 = BatchNorm(256, affine=true, track_stats=true),  # 512 parameters, plus 513\n                ),\n            ),\n        ),\n        layer_5 = Chain(\n            layer_1 = Parallel(\n                connection = addact(NNlib.relu, ...),\n                layer_1 = Chain(\n                    layer_1 = Conv((1, 1), 256 => 512, stride=2, use_bias=false),  # 131_072 parameters\n                    layer_2 = BatchNorm(512, affine=true, track_stats=true),  # 1_024 parameters, plus 1_025\n                ),\n                layer_2 = Chain(\n                    layer_1 = Conv((3, 3), 256 => 512, pad=1, stride=2, use_bias=false),  # 1_179_648 parameters\n                    layer_2 = BatchNorm(512, affine=true, track_stats=true),  # 1_024 parameters, plus 1_025\n                    layer_3 = WrappedFunction(relu),\n                    layer_4 = Conv((3, 3), 512 => 512, pad=1, use_bias=false),  # 2_359_296 parameters\n                    layer_5 = BatchNorm(512, affine=true, track_stats=true),  # 1_024 parameters, plus 1_025\n                ),\n            ),\n            layer_2 = Parallel(\n                connection = addact(NNlib.relu, ...),\n                layer_1 = NoOpLayer(),\n                layer_2 = Chain(\n                    layer_1 = Conv((3, 3), 512 => 512, pad=1, use_bias=false),  # 2_359_296 parameters\n                    layer_2 = BatchNorm(512, affine=true, track_stats=true),  # 1_024 parameters, plus 1_025\n                    layer_3 = WrappedFunction(relu),\n                    layer_4 = Conv((3, 3), 512 => 512, pad=1, use_bias=false),  # 2_359_296 parameters\n                    layer_5 = BatchNorm(512, affine=true, track_stats=true),  # 1_024 parameters, plus 1_025\n                ),\n            ),\n        ),\n    ),\n    layer_2 = Chain(\n        layer_1 = AdaptiveMeanPool((1, 1)),\n        layer_2 = FlattenLayer{Static.StaticInt{3}}(static(3)),\n        layer_3 = Dense(512 => 37, σ),  # 18_981 parameters\n    ),\n)         # Total: 11_195_493 parameters,\n          #        plus 9_620 states.\n```\n:::\n:::\n\n\n\n### Testing the ResNet Model with Sample Data\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\n# Create dummy input to test the model\nx_test = rand(rng, Float32, 64, 64, 3, 2)  # (height, width, channels, batch_size)\nresnet_model(x_test, resnet_ps, Lux.testmode(resnet_st))\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n(Float32[0.30450302 0.30915502; 0.37083414 0.3660484; … ; 0.6346178 0.65124583; 0.30676535 0.30921096], (layer_1 = (layer_1 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()), layer_3 = NamedTuple()), layer_2 = (layer_1 = (layer_1 = NamedTuple(), layer_2 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()), layer_3 = NamedTuple(), layer_4 = NamedTuple(), layer_5 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()))), layer_2 = (layer_1 = NamedTuple(), layer_2 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()), layer_3 = NamedTuple(), layer_4 = NamedTuple(), layer_5 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}())))), layer_3 = (layer_1 = (layer_1 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}())), layer_2 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()), layer_3 = NamedTuple(), layer_4 = NamedTuple(), layer_5 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()))), layer_2 = (layer_1 = NamedTuple(), layer_2 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()), layer_3 = NamedTuple(), layer_4 = NamedTuple(), layer_5 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}())))), layer_4 = (layer_1 = (layer_1 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}())), layer_2 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()), layer_3 = NamedTuple(), layer_4 = NamedTuple(), layer_5 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()))), layer_2 = (layer_1 = NamedTuple(), layer_2 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()), layer_3 = NamedTuple(), layer_4 = NamedTuple(), layer_5 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}())))), layer_5 = (layer_1 = (layer_1 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}())), layer_2 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()), layer_3 = NamedTuple(), layer_4 = NamedTuple(), layer_5 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()))), layer_2 = (layer_1 = NamedTuple(), layer_2 = (layer_1 = NamedTuple(), layer_2 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()), layer_3 = NamedTuple(), layer_4 = NamedTuple(), layer_5 = (running_mean = Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], running_var = Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], training = Val{false}()))))), layer_2 = (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple())))\n```\n:::\n:::\n\n\n\n### Training the ResNet Model\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nresnet_epochs = 3\n# Evaluate initial performance\nif isfile(\"resnet_trained_model.jld2\")\n    @load \"resnet_trained_model.jld2\" resnet_ps_trained resnet_st_trained resnet_train_losses resnet_test_losses\nelse\n    initial_train_loss, initial_test_loss = init_evaluate_model(resnet_model, resnet_ps, resnet_st, train_loader, test_loader)\n    @printf \"Initial ResNet: Train Loss %4.5f, Test Loss %4.5f\\n\" initial_train_loss initial_test_loss\n    # Train the ResNet model\n    resnet_train_state, resnet_train_losses, resnet_test_losses = train_model!(resnet_model, resnet_ps, resnet_st, train_loader, test_loader; op=Adam(0.0005f0), epochs=resnet_epochs)\n\n    # Prepend initial losses\n    prepend!(resnet_train_losses, initial_train_loss)\n    prepend!(resnet_test_losses, initial_test_loss)\n\n    # Save the trained model\n    resnet_ps_trained, resnet_st_trained = resnet_train_state.parameters, resnet_train_state.states\n    @save \"resnet_trained_model.jld2\" resnet_ps_trained resnet_st_trained resnet_train_losses resnet_test_losses\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n4-element Vector{Symbol}:\n :resnet_ps_trained\n :resnet_st_trained\n :resnet_train_losses\n :resnet_test_losses\n```\n:::\n:::\n\n\n\n### Visualizing ResNet Training Results\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\n# Visualize the evolution of the training and testing loss for ResNet\nfig = Figure()\nax = Axis(fig[1, 1],\n    xlabel=\"Epoch\",\n    ylabel=\"Mean Squared Error\",\n    title=\"ResNet Training and Testing Loss Evolution\",\n)\nscatterlines!(0:resnet_epochs, resnet_train_losses, linewidth=3, color=:blue, label=\"ResNet Training Loss\")\nscatterlines!(0:resnet_epochs, resnet_test_losses, linewidth=3, color=:red, label=\"ResNet Testing Loss\")\naxislegend(ax, position=:rt)\n\nfig\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n![](index_files/figure-typst/cell-22-output-1.svg){}\n:::\n:::\n\n\n\n### Comparing ResNet with Original CNN\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\n# Compare RMSE of ResNet with the original CNN\nresnet_rmse = sqrt(resnet_test_losses[end])\ncnn_rmse = sqrt(test_losses[end])\nsimple_rmse_ref = 0.16194\n\n@info \"Original CNN RMSE: \" cnn_rmse\n@info \"ResNet RMSE: \" resnet_rmse\n@info \"Reference simple method RMSE: \" simple_rmse_ref\n\nresnet_improvement = round(((cnn_rmse - resnet_rmse) / cnn_rmse * 100), digits=2)\n\nif resnet_rmse < cnn_rmse\n    println(\"\\nResNet outperforms our original CNN by $(resnet_improvement)%!\")\n    println(\"The skip connections in ResNet help with gradient flow during training, \n        allowing the network to learn more complex features.\"\n    )\nelse\n    println(\"\\nResNet doesn't outperform our original CNN.\")\n    println(\"This could be due to:\")\n    println(\"1. Limited training time (ResNet is much larger and needs more epochs)\")\n    println(\"2. Potential overfitting due to the larger model size\")\n    println(\"3. The original CNN might be better suited for this specific dataset size\")\nend\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n┌ Info: Original CNN RMSE: \n└   cnn_rmse = 0.11684338f0\n┌ Info: ResNet RMSE: \n└   resnet_rmse = 0.1086326f0\n┌ Info: Reference simple method RMSE: \n└   simple_rmse_ref = 0.16194\n\nResNet outperforms our original CNN by 7.03%!\nThe skip connections in ResNet help with gradient flow during training, \n        allowing the network to learn more complex features.\n```\n:::\n:::\n\n\n\n## References\n\n- [Galaxy Zoo - The Galaxy Challenge | Kaggle](https://www.kaggle.com/competitions/galaxy-zoo-the-galaxy-challenge/overview)\n- [My solution for the Galaxy Zoo challenge – Sander Dieleman](https://sander.ai/2014/04/05/galaxy-zoo.html)\n\n",
    "supporting": [
      "index_files/figure-typst"
    ],
    "filters": []
  }
}