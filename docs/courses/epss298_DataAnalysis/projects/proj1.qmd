---
title: Project 1
subtitle: Transiting Exoplanet
engine: julia
---

> Your team detected a planet candidate in the data from the Transiting Exoplanet Survey Satellite (TESS). The data is very noisy, but you are relatively confident the planet is there.  
 
> Based on the TESS data, you can predict that the center of the next transit will be between the  time t = 1.212 days and t = 1.362 days [Note: t is measured relative to an arbitrary reference time]. The TESS data also tell you that the radius of the planet is between 1% and 10% the radius of the star. Unfortunately, you don't know where the planet crosses the star, i.e. the impact  parameter is unconstrained between 0 and 1. Assume that the orbital period is exactly known to be 3.0 days. 
 
> You wrote a proposal and successfully convinced the time allocation committee of the James Webb Space Telescope (JWST) to obtain new very precise data for you. YAY!!! 
 
> You receive the data in Project1_JWST_data.csv. The errors are 10-4=0.01% on each data point in the light curve. 
 
> From these data, you want to determine new estimates with uncertainties for the transit time, the planet-to-star radius ratio, and the impact parameter. 

> Batman: https://lkreidberg.github.io/batman/docs/html/index.html 

```{julia}
dir = "docs/courses/epss298_DataAnalysis"
if isdir(dir)
    cd(dir)
    Pkg.activate(".")
    Pkg.instantiate()
    cd("projects")
end
```


```{julia}
using CondaPkg
using PythonCall
CondaPkg.add("batman-package")

const batman = pyimport("batman")
const pyTransitModel = batman.TransitModel
```

```{julia}
using CSV, DataFrames
using CairoMakie
path = "./Project1_JWST_data.csv"
data = CSV.read(path, DataFrame)

f = Figure()
plot(f[1, 1], data.time, data.flux)
f
```

```{julia}
using DrWatson

function TransitParams(; ecc=0.0, w=0.0, limb_dark="quadratic", kwargs...)
    params = batman.TransitParams()
    for (key, value) in merge(kwargs, @dict(ecc, w, limb_dark))
        setproperty!(params, key, value)
    end
    return params
end

TransitModel(params, time) = pyTransitModel(params, Py(time).to_numpy())

function light_curve(params, time)
    m = TransitModel(params, time)
    flux = m.light_curve(params)
    return PyArray(flux)
end
```

## Part A
 
### Step 1: Define the physical model 
Write a function for your physical "forward" model that takes in a vector with these three parameters: 

```{julia}
t0 = 1.311544
rp = 0.01
b = 0.1

per = 3
a = 15
inc = acosd(b / a)
params = TransitParams(; t0, per, rp, a, inc, u=[0.3, 0.3])
flux = light_curve(params, data.time)        #calculates light curve
plot(f[2, 1], data.time, flux)
f
```

### Step 2: Define the Bayesian analysis 

1. Write the given prior information as a log-prior function
2. Write a log-likelihood function
3. Write a log-probability function

```{julia}
# Define the log-prior function
function log_prior(params)
    t0, rp, b = params
    # Prior constraints from problem description:
    # Transit time between 1.212 and 1.362 days
    # Planet radius between 1% and 10% of star radius
    # Impact parameter between 0 and 1
    if 1.212 <= t0 <= 1.362 && 0.01 <= rp <= 0.10 && 0 <= b <= 1
        return 0.0  # Log of 1, uniform prior within constraints
    else
        return -Inf  # Log of 0, zero probability outside constraints
    end
end

# Define the log-likelihood function
function log_likelihood(params, time, observed_flux, error)
    t0, rp, b = params

    # Fixed parameters
    per = 3.0  # Period in days
    a = 15.0   # Semi-major axis in stellar radii
    inc = acosd(b / a)  # Inclination in degrees
    u = [0.3, 0.3]    # Limb darkening coefficients

    # Create transit parameters
    transit_params = TransitParams(; t0, per, rp, a, inc, u)
    model_flux = light_curve(transit_params, time)

    # Calculate log-likelihood (assuming Gaussian errors)
    # log(L) = -0.5 * sum((observed - model)^2 / sigma^2) - 0.5 * N * log(2π) - sum(log(sigma))
    # Since sigma is constant, we can simplify
    residuals = observed_flux .- model_flux
    chi_squared = sum((residuals ./ error) .^ 2)
    return -0.5 * chi_squared
end

# Define the log-probability function (posterior)
function log_probability(params, time, observed_flux, error)
    return log_prior(params) + log_likelihood(params, time, observed_flux, error)
end
```

## Step 3: Demonstrate solution on a grid 

Determine new estimates with uncertainties of the planet-to-star radius ratio and the impact parameter. Fix the transit mid-time to t0 = 1.311544 days. Make a 50x50 grid that explores planet-to-star radius ratios between 0.05275 and 0.53505 as well as impact parameters between 0 and 0.3.

1. Plot the joint posterior distribution with plt.pmeshcolor and mark the best fit with a marker 
2. Plot the marginalized posterior distributions for the planet-to-star radius ratio and the impact parameters.  
3. Calculate the mean and +/-1 sigma uncertainties for both parameters. Mark the mean value with a solid vertical line in the figure created in Step 3.2. Make the +/-1 sigma uncertainties with dashed vertical lines. Report the best estimates (mean and uncertainty) for both parameters quantitatively. 
4. Calculate the covariance matrix that best represents the joint posterior distribution. What is the correlation coefficient between the planet-to-star radius ratios and the impact parameter? Plot the 68% and 95% confidence regions onto the figure created in Step 3.1.


```{julia}
using LinearAlgebra  # For eigen decomposition and other matrix operations
using Statistics     # For statistical functions

# Fix transit mid-time to t0 = 1.311544 days
fixed_t0 = 1.311544

# Create a 50x50 grid for rp and b
n_grid = 50
rp_grid = range(0.05275, 0.53505, length=n_grid)
b_grid = range(0.0, 0.3, length=n_grid)

# Initialize the posterior grid
posterior_grid = zeros(n_grid, n_grid)

# Calculate the log posterior for each grid point
for (i, rp) in enumerate(rp_grid)
    for (j, b) in enumerate(b_grid)
        params = [fixed_t0, rp, b]
        # Use fixed error value of 1e-4 (0.01%) as mentioned in the problem
        posterior_grid[i, j] = log_probability(params, data.time, data.flux, 1e-4)
    end
end

# Convert log posterior to posterior (subtract max to avoid numerical issues)
posterior_grid = exp.(posterior_grid .- maximum(posterior_grid))
# Normalize the posterior
posterior_grid = posterior_grid ./ sum(posterior_grid)

# Find the maximum posterior point
max_idx = argmax(posterior_grid)
best_rp = rp_grid[max_idx[1]]
best_b = b_grid[max_idx[2]]
println("Best fit values: rp = $(best_rp), b = $(best_b)")

# 1. Plot the joint posterior distribution
fig = Figure(size=(1000, 800))

# Joint posterior plot
ax1 = Axis(fig[1, 1],
    xlabel="Planet-to-star radius ratio (rp)",
    ylabel="Impact parameter (b)",
    title="Joint Posterior Distribution")

hm = heatmap!(ax1, rp_grid, b_grid, posterior_grid', colormap=:viridis)
scatter!(ax1, [best_rp], [best_b], color=:red, markersize=15)
Colorbar(fig[1, 2], hm, label="Posterior Probability")

# # 2. Plot the marginalized posterior distributions
# # Marginalize over b to get posterior for rp
# rp_posterior = vec(sum(posterior_grid, dims=2))
# rp_posterior ./= sum(rp_posterior)  # Normalize

# # Marginalize over rp to get posterior for b
# b_posterior = vec(sum(posterior_grid, dims=1))
# b_posterior ./= sum(b_posterior)  # Normalize

# # Plot marginalized posterior for rp
# ax2 = Axis(fig[2, 1],
#     xlabel="Planet-to-star radius ratio (rp)",
#     ylabel="Probability",
#     title="Marginalized Posterior for rp")
# lines!(ax2, rp_grid, rp_posterior)

# # Plot marginalized posterior for b
# ax3 = Axis(fig[2, 2],
#     xlabel="Impact parameter (b)",
#     ylabel="Probability",
#     title="Marginalized Posterior for b")
# lines!(ax3, b_grid, b_posterior)

# # 3. Calculate mean and uncertainties
# # For rp
# rp_mean = sum(rp_grid .* rp_posterior)
# rp_var = sum((rp_grid .- rp_mean) .^ 2 .* rp_posterior)
# rp_std = sqrt(rp_var)

# # For b
# b_mean = sum(b_grid .* b_posterior)
# b_var = sum((b_grid .- b_mean) .^ 2 .* b_posterior)
# b_std = sqrt(b_var)

# # Add mean and +/- 1 sigma to the marginalized plots
# vlines!(ax2, [rp_mean], color=:black, linewidth=2)
# vlines!(ax2, [rp_mean - rp_std, rp_mean + rp_std], color=:black, linestyle=:dash)

# vlines!(ax3, [b_mean], color=:black, linewidth=2)
# vlines!(ax3, [b_mean - b_std, b_mean + b_std], color=:black, linestyle=:dash)

# # Print the results
# println("Planet-to-star radius ratio (rp):")
# println("Mean: $(rp_mean), Uncertainty: ±$(rp_std)")
# println("Impact parameter (b):")
# println("Mean: $(b_mean), Uncertainty: ±$(b_std)")

# # 4. Calculate the covariance matrix
# # Create meshgrid for the 2D parameter space
# rp_2d = repeat(rp_grid, 1, n_grid)
# b_2d = repeat(b_grid', n_grid, 1)

# # Calculate covariance matrix elements
# cov_rp_rp = sum((rp_2d .- rp_mean) .^ 2 .* posterior_grid)
# cov_b_b = sum((b_2d .- b_mean) .^ 2 .* posterior_grid)
# cov_rp_b = sum((rp_2d .- rp_mean) .* (b_2d .- b_mean) .* posterior_grid)

# cov_matrix = [cov_rp_rp cov_rp_b; cov_rp_b cov_b_b]
# println("Covariance matrix:")
# println(cov_matrix)

# # Calculate correlation coefficient
# corr_coef = cov_rp_b / (sqrt(cov_rp_rp) * sqrt(cov_b_b))
# println("Correlation coefficient: $(corr_coef)")

# # Add confidence regions to joint posterior plot
# # Helper function to create confidence ellipses
# function confidence_ellipse(cov_matrix, mean, confidence=0.68)
#     # For 2D, 68% confidence = 2.3, 95% confidence = 6.0
#     scale = confidence == 0.68 ? 2.3 : 6.0

#     # Eigendecomposition of covariance matrix
#     eigvals, eigvecs = eigen(cov_matrix)

#     # Create ellipse points
#     theta = range(0, 2π, length=100)
#     ellipse = zeros(length(theta), 2)

#     for (i, t) in enumerate(theta)
#         # Create the ellipse using the eigenvalues and eigenvectors
#         ellipse[i, :] = mean .+ sqrt(scale) .* (sqrt.(eigvals) .* [cos(t), sin(t)]) * eigvecs'
#     end

#     return ellipse[:, 1], ellipse[:, 2]
# end

# # Add 68% confidence ellipse
# # x_68, y_68 = confidence_ellipse(cov_matrix, [rp_mean, b_mean], 0.68)
# # lines!(ax1, x_68, y_68, color=:white, linewidth=2, label="68% confidence")

# # Add 95% confidence ellipse
# # x_95, y_95 = confidence_ellipse(cov_matrix, [rp_mean, b_mean], 0.95)
# # lines!(ax1, x_95, y_95, color=:red, linewidth=2, label="95% confidence")

# # Add legend to joint plot1
# axislegend(ax1, position=:lt)

fig
```

## Part B
 
Step 4: Solve the full problem using MCMC and Nested Sampling 
Determine new estimates with uncertainties of the transit time, the planet-to-star radius ratio, and 
the impact parameter 
1. Using Emcee. Make all possible plots and quantitative assessments to convince the reviewer that your results are converged 
2. Using Dynesty. Make all possible plots and quantitative assessments to convince the reviewer  that your results are converged  
 
Step 5: Investigate whether you model is a good fit to the data 
Investigate the residuals. What do you think? Quantitatively and graphically assess whether your model is a good fit to the data. 
 
Step 6: Refine your physical model 
1. What could explain your findings in Part 4? Tip: When a distant observer sees a transit of the Earth in front of the sun, would it only be the Earth that is transiting at that time? 
2. Code a new physical "forward" model and log-likelihood function that better explains the data.  
3. Use Dynesty to find the constraints of both objects. Treat the moon like another body transiting shortly before or after. Use the same prior for the moon. That makes six parameters. 
4. Make plots to convince the reviewer that your results are converged  
5. Determine quantitatively whether the model justifies applying this more complex model? How confident are you that you detected a moon? 
6. Summarize your results for the parameters for each object? 
7. Why do you get a multi-modal solution? What could you do to avoid this in this simple example? 
 
Step 7: 
Describe in a few sentences one example for a problem or data set that you could analogously solve in your research domain? 


## Reference

- [DACE tutorial on photometry](https://dace.unige.ch/tutorials/?tutorialId=32)
